{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89722864-13c6-4ea9-9f7c-e9326934e8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniforge3/envs/tf-2.0/lib/python3.9/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute and \", return_tensors=\"pt\")\n",
    "output = model.generate(\n",
    "    **inputs, return_dict_in_generate=True, output_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca228b26-f575-432c-98ed-081614e5e0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreedySearchDecoderOnlyOutput(sequences=tensor([[15496,    11,   616,  3290,   318, 13779,   290,   220, 17479,    13,\n",
       "           314,  1101,   407,  1654,   611,   673,   338,   257,   922,  3290]]), scores=(tensor([[-64.3024, -65.3176, -66.9861,  ..., -78.9404, -72.8338, -67.7866]]), tensor([[-73.2116, -75.7243, -81.9891,  ..., -90.8769, -88.5996, -78.7203]]), tensor([[-146.1742, -146.3822, -147.2089,  ..., -158.8192, -157.9572,\n",
       "         -142.1863]]), tensor([[-175.1702, -174.6989, -179.6604,  ..., -186.0345, -176.7065,\n",
       "         -176.9384]]), tensor([[-149.3362, -149.3672, -152.5345,  ..., -158.5597, -155.5005,\n",
       "         -151.1143]]), tensor([[-144.5121, -146.0198, -154.7363,  ..., -155.6022, -153.6687,\n",
       "         -147.9046]]), tensor([[-139.3071, -139.9813, -148.0197,  ..., -150.1555, -150.1833,\n",
       "         -142.5465]]), tensor([[-112.5984, -112.5419, -118.2547,  ..., -120.3223, -119.8586,\n",
       "         -113.9022]]), tensor([[-144.4347, -142.7842, -150.5634,  ..., -152.9679, -146.4665,\n",
       "         -144.7417]]), tensor([[-141.1149, -140.6125, -145.6440,  ..., -147.4012, -144.3897,\n",
       "         -142.6430]]), tensor([[-118.4239, -117.7450, -122.0197,  ..., -127.3702, -124.4989,\n",
       "         -118.6751]]), tensor([[-106.5581, -105.3646, -110.1932,  ..., -114.3858, -112.6030,\n",
       "         -108.8391]])), attentions=None, hidden_states=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a660b15b-17b4-42e5-a821-8f5756329dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello, my dog is cute and icky. I'm not sure if she's a good dog\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output['sequences'].numpy().squeeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-2.0]",
   "language": "python",
   "name": "conda-env-tf-2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
